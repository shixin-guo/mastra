---
title: "Example: Insert Embeddings in LibSQL | RAG | Mastra Docs"
description: Example of using Mastra to store embeddings in LibSQL for similarity search.
---

import { GithubLink } from "../../../components/github-link";

# Insert Embedding in LibSQL

After generating embeddings, you need to store them in a vector database for similarity search. The `DefaultVectorDB` class provides methods to create collections and insert embeddings into LibSQL, a fork of SQLite with vector extensions. This example shows how to store embeddings in LibSQL for later retrieval.

```tsx copy
import { openai } from "@ai-sdk/openai";
import { DefaultVectorDB } from "@mastra/core/storage";
import { MDocument } from "@mastra/rag";
import { embedMany } from "ai";

const doc = MDocument.fromText("Your text content...");

const chunks = await doc.chunk();

const { embeddings } = await embedMany({
  values: chunks.map((chunk) => chunk.text),
  model: openai.embedding("text-embedding-3-small"),
});

const libsql = new DefaultVectorDB({
  connectionUrl: process.env.DATABASE_URL,
  authToken: process.env.DATABASE_AUTH_TOKEN, // Optional: for Turso cloud databases
});

await libsql.createIndex("test_collection", 1536);

await libsql.upsert(
  "test_collection",
  embeddings,
  chunks?.map((chunk) => ({ text: chunk.text })),
);
```

<br />

<br />
<hr className="dark:border-[#404040] border-gray-300" />
<br />
<br />
<GithubLink
  link={
    "https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/insert-embedding-in-libsql"
  }
/>
