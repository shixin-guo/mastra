---
title: "Reference: Agent.stream() | Streaming | Agents | Mastra Docs"
description: Documentation for the `.stream()` method in Mastra agents, which enables real-time streaming of responses.
---

# `stream()`

The `stream()` method enables real-time streaming of responses from an agent. This method accepts `messages` and an optional `options` object as parameters, similar to `generate()`.

## Parameters

### `messages`

The `messages` parameter can be:

- A single string
- An array of strings
- An array of message objects with `role` and `content` properties

#### Message Object Structure

```typescript
interface Message {
  role: 'system' | 'user' | 'assistant';
  content: string;
}
```

### `options` (Optional)

An optional object that can include:

<PropertiesTable
  content={[
    {
      name: "options",
      type: "object",
      required: false,
      description: "Additional options for the `stream` method.",
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "output",
              type: "Zod schema | JsonSchema7",
              isOptional: true,
              description: "Defines the expected structure of the output. Can be a JSON Schema object or a Zod schema.",
            },
            {
              name: "experimental_output",
              type: "Zod schema | JsonSchema7",
              isOptional: true,
              description: "Enables structured output generation alongside text generation and tool calls. The model will generate responses that conform to the provided schema.",
            },
            {
              name: "context",
              type: "CoreMessage[]",
              isOptional: true,
              description: "Additional context messages to provide to the agent.",
            },
            {
              name: "threadId",
              type: "string",
              isOptional: true,
              description: "Identifier for the conversation thread. Allows for maintaining context across multiple interactions.",
            },
            {
              name: "resourceId",
              type: "string",
              isOptional: true,
              description: "Identifier for the user or resource interacting with the agent.",
            },
            {
              name: "onFinish",
              type: "(result: string) => Promise<void> | void",
              isOptional: true,
              description: "Callback function called when streaming is complete.",
            },
            {
              name: "onStepFinish",
              type: "(step: string) => void",
              isOptional: true,
              description: "Callback function called after each step during streaming.",
            },
            {
              name: "maxSteps",
              type: "number",
              isOptional: true,
              defaultValue: "5",
              description: "Maximum number of steps allowed during streaming.",
            },
            {
              name: "toolsets",
              type: "ToolsetsInput",
              isOptional: true,
              description: "Additional toolsets to make available to the agent during this stream.",
            },
            {
              name: "temperature",
              type: "number",
              isOptional: true,
              description: "Controls randomness in the model's output. Higher values (e.g., 0.8) make the output more random, lower values (e.g., 0.2) make it more focused and deterministic.",
            }
          ]
        }
      ]
    }
  ]}
/>

## Returns

The return value of the `stream()` method depends on the options provided, specifically the `output` option.

### PropertiesTable for Return Values

<PropertiesTable
  content={[
    {
      name: "textStream",
      type: "AsyncIterable<string>",
      required: false,
      description: "An async iterable stream of text chunks. Present when output is 'text'.",
    },
    {
      name: "objectStream",
      type: "AsyncIterable<object>",
      required: false,
      description: "An async iterable stream of structured data. Present when a schema is provided.",
    },
    {
      name: "object",
      type: "Promise<object>",
      required: false,
      description: "A promise that resolves to the final structured output when using a schema.",
    }
  ]}
/>

## Examples

### Basic Text Streaming

```typescript
const stream = await myAgent.stream([
  { role: "user", content: "Tell me a story." }
]);

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

### Structured Output Streaming with Thread Context

```typescript
const schema = {
  type: 'object',
  properties: {
    summary: { type: 'string' },
    nextSteps: { type: 'array', items: { type: 'string' } }
  },
  required: ['summary', 'nextSteps']
};

const response = await myAgent.stream(
  "What should we do next?",
  {
    output: schema,
    threadId: "project-123",
    onFinish: text => console.log("Finished:", text)
  }
);

for await (const chunk of response.textStream) {
  console.log(chunk);
}

const result = await response.object;
console.log("Final structured result:", result);
```

The key difference between Agent's `stream()` and LLM's `stream()` is that Agents maintain conversation context through `threadId`, can access tools, and integrate with the agent's memory system.
